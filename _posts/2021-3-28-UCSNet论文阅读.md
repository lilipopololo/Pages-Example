---
layout: post
title: UCSNet论文阅读
category: blog
description: 写博客这个这么古老的行为，还有必要拿出来说吗，我看有。
---

## UCSNet 论文阅读

#### 平面扫描法

- 平面扫面算法将深度范围内分为一个个平面，平行平面足够密集，空间被分割的足够细，空间物体表面上的一点 M 一定位于平行平面中的其中一个平面上。又有另一个点 M’，假定这个点也在这个平面上，但是它不位于任何可见物体的表面上，这样的点很有可能投影到每个可见摄像机上，并不是同样的颜色
  ![2021-03-28123000.jpg](/images/githubpages/2021-03-28123000.jpg)
- 单应矩阵就是通过线代的方法通过矩阵表示不同视角的相机平面对应点的关系（2D-》3D-》2D）。主要的部分有内参矩阵和外参矩阵（也可以单分为平移旋转），内参矩阵记录相机的参数，外参矩阵主要由物点和相机的空间关系决定。例如参考图像上的一点和原图像的对应点可以表示为 x'=Hx(x 为参考图像),H 时 Homograph 的缩写，也就是单应矩阵。
- 损失函数也就是 cost function，由于上面的原因，所以不能只利用两点颜色相同来匹配对应点，需要利用每个点的窗口信息，因此需要在两个窗口每个对应像素求得绝对差然后镜像求和，由于时多视点因此还需要对多个源视点和参考视点获得的视图进行上述操作然后求和，其中可以对源视图添加计算光照变化的增益因子。计算出来的 loss function 取最小值就是对应视图中的对应点。

#### UCSnet

- 以前的方法依赖于平面空间扫描，PSV，并且对每一个深度平面有着固定的深度假设，但是这样的前提是密集的对平面采样并且需要很高的精度，然而由于内存有限，高分辨率的深度几乎是不切实际的。作者提出了 ATV（adaptive thin volume）自适应薄空间扫描（volume 空间）。在一个 ATV 中，每一个深度片面的深度假设都在变化。UCSnet 有三个阶段，第一个阶段将小的 PSV 估计成为低像素的深度，两个 ATV 在下面得阶段将深度优化为具有更高像素和更高精确度的深度。作者的 ATV 只包含少量的平面且只占用较低的显存和计算资源。同时他在碰到小的无法确定的间隔（interval）情况下，能有效地划分局部的深度范围。它计划使用基于方差的不确定性估计去自适应的构造 ATV;这种可分的操作更加合理和精细的空间分区。我们的多阶段的框架逐步的将庞大的场景空间使用越来越高分辨率和精度逐步划分为，这样使得高完整度和高精确性的重建可以由粗糙到精细的方式实现。
- 推断 3D 场景在 3D 可视化，场景理解，机器人和自主驾驶多有应用。最近在 MVS 上的成功是 3d 卷积在平面空间扫描上的应用，这能够又凶啊的推断多视图的对应点。然而
