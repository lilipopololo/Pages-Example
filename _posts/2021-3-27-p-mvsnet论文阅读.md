---
layout: post
title: p-mvsnet阅读
category: blog
description: 写博客这个这么古老的行为，还有必要拿出来说吗，我看有。
---

- from Pyramid Multi-view Stereo Net with Self-adaptive View Aggregation Hongwei Yi PKU

- pmvs 同样是 mvsnet 系列的网络。mvsnet 从 Yao Yao 开始,逐步成为了 2020 年的热点研究方向。
  引言提到了他们的 Vamvsnet(没有引用也没有搜到)。PMVS 是一种金字塔结构，能够自适应的聚集不同视角的视图，以前基于 MVS 的深度学习方法使用均方差的方式生成代价量。他的方法使用两种新的方法 Pixel-Wise View 和 Voxel-Wise Views 聚合不同的视图。实验通过 DTU 数据集训练出结果，并且生成结果能够和 T&T 数据集上的方法具有相当的表现

- 最近的方法可以几乎不通过立体匹配取解决匹配的歧义性（Deepmvs: Learningmulti-view stereopsis. In: CVPR (2018)Dpsnet: End-to-end deep plane sweep stereo.）他们遵循所有视角获取的视图再代价量空间中有同样的贡献。例如 MVSnet 和 RMVSnet 再多个视角的代价量空间上使用了均方差的操作。而 DPSnet 使用了均方值操作。然而视图的不同之处在于不同的照明条件（DTU）相机外参，场景的变量。作者使用自适应融合模块可以更好的增强匹配的区域，抑制不匹配的区域(?)
- 第二，多尺度信息没有利用，ACMM（Xu, Q., Tao, W.: Multi-scale geometric consistency guided multi-view stereo）逐步处理递归获取由粗到精细的深度图。他通过多尺度将金字塔的不同尺度的深度图并行聚合起来生成精细深度图
  ![image](\images\githubpages\2021-03-27200422.jpg)
- 具体过程
  设置好每一组图片中的参考视图以及参考视图临近的视图，分别用 i=0 和 i=1，2...n 表示 n 表示多视图图像的数量。如图对 n 个图像使用 k 个下采样层构成 K-Level 图像金字塔，k=0 表示原始图像
- 下一步是 VAMVSnet（有点模仿 MVSnet？）
  ![image](\images\githubpages\2021-03-27202640.jpg)
  MVSnet 是特征提取，单应，U 型金字塔，深度估计（几层 conv）
  它先是 N 支用来接收图像，U 型金字塔，（特征得到后 1/4 下采样），然后使用差分单应变换，将其他源视图对应到参考视图的对应点位，目的是将每一组对应的特征点位进行合并，将 W，H，D，C 的特征空间变成 W，H，D，C（C 为一组对应点 Vi=V0,V1,V2....）。以前的工作对输入的特征空间求均方差,作者觉得不够合理，被遮挡的图像内容和相机位置应该被去除，没有遮挡的视图可以提供更加准确的几何和光学信息所以作者使用了自适应视图聚合模块。总共费为两种不同的逐像素的视图聚合模块 Pixel-Wise View 和 Voxel-Wise Views 。Pixel-Wise View 类似 ACMM。 Voxel-Wise Views 模块是一种使用 3D 注意力机制 3D 特征空间中的每个体素来学习自身的权重。
  Pixel-Wise View
